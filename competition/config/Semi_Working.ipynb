{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "config = {\n",
    "    \"batchsize_train\": 30,\n",
    "    \"batchsize_val\": 30,\n",
    "    \"shuffle_train\": True,\n",
    "    \"shuffle_val\": False,\n",
    "    \"num_workers_train_loader\": 4,\n",
    "    \"num_workers_val_loader\": 4,\n",
    "    \"epochs\": 4,\n",
    "    \"lr\": 0.0001,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import h5py\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GateDetectionNet(nn.Module):\n",
    "    def __init__(self, num_gates=6, num_outputs_per_gate=13, conf_threshold=0.5):\n",
    "        super(GateDetectionNet, self).__init__()\n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        # Max pooling layers\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        # Calculate the flattened size after convolution and pooling layers.\n",
    "        # Assuming input size of (3, 480, 640)\n",
    "        flattened_size = 64 * (480 // 8) * (640 // 8)\n",
    "\n",
    "        self.fc1 = nn.Linear(flattened_size, 1024)\n",
    "        self.fc11 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "\n",
    "        # Predict gate attributes (x, y, visibility) for each gate\n",
    "        self.gate_pred_layer = nn.Linear(128, num_gates * num_outputs_per_gate)\n",
    "\n",
    "        self.num_gates = num_gates\n",
    "        self.num_outputs_per_gate = num_outputs_per_gate\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with ReLU activations and max pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Apply max pooling after relu\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Apply max pooling again after relu\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # Apply max pooling again after relu\n",
    "\n",
    "        # Flatten the feature maps to pass into the fully connected layers\n",
    "        x = torch.flatten(x, 1)  # Flatten all dimensions except batch\n",
    "\n",
    "        # Fully connected layers with ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc11(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "\n",
    "        # Predict gate attributes\n",
    "        gate_pred = self.gate_pred_layer(x)\n",
    "\n",
    "        # Reshape predictions to (batch_size, num_gates, num_outputs_per_gate)\n",
    "        gate_pred = gate_pred.view(x.size(0), self.num_gates, self.num_outputs_per_gate)\n",
    "\n",
    "        # Apply constraints to the x, y, and visibility values\n",
    "        gate_pred[..., 0::3] = torch.sigmoid(\n",
    "            gate_pred[..., 0::3]\n",
    "        )  # Constrain all x values to [0, 1]\n",
    "        gate_pred[..., 1::3] = torch.sigmoid(\n",
    "            gate_pred[..., 1::3]\n",
    "        )  # Constrain all y values to [0, 1]\n",
    "        gate_pred[..., 2::3] = (\n",
    "            torch.sigmoid(gate_pred[..., 2::3]) * 2\n",
    "        )  # Constrain visibility to [0, 2]\n",
    "\n",
    "        return gate_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import hdf5plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = GateDetectionNet()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# force cpu as dvice\n",
    "# device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "class GateDetectionDataset(Dataset):\n",
    "    def __init__(self, h5_file_path):\n",
    "        \"\"\"\n",
    "        Initialize the dataset by loading the HDF5 file.\n",
    "\n",
    "        Args:\n",
    "            h5_file_path (str): Path to the HDF5 file containing images and targets.\n",
    "        \"\"\"\n",
    "        # Open the HDF5 file\n",
    "        self.h5f = h5py.File(h5_file_path, \"r\")\n",
    "\n",
    "        # Load images and targets into the dataset\n",
    "        self.images = self.h5f[\"images\"]\n",
    "        self.targets = [\n",
    "            self.h5f[f\"targets/{i:05d}\"][()] for i in range(len(self.images))\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of samples in the dataset.\"\"\"\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve a sample from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            image (torch.Tensor): The image as a torch tensor.\n",
    "            target (torch.Tensor): The corresponding target for the image.\n",
    "        \"\"\"\n",
    "        # Load image and target\n",
    "        image = self.images[idx]  # Image as numpy array\n",
    "        target = self.targets[idx]  # Target as numpy array\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        image = torch.tensor(image, dtype=torch.float32)  # Convert to float tensor\n",
    "        target = torch.tensor(target, dtype=torch.float32)  # Convert to float tensor\n",
    "\n",
    "        ones = torch.ones(\n",
    "            (target.shape[0], 1), dtype=torch.float32\n",
    "        )  # Create a tensor of ones\n",
    "        target = torch.cat(\n",
    "            [target, ones], dim=1\n",
    "        )  # Append the ones to make (nr_of_gates, 13)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Close the HDF5 file when the object is deleted.\"\"\"\n",
    "        self.h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "\n",
    "file_paths = \"/kaggle/input/mission-impassable/autonomous_flight-01a-ellipse.h5\"\n",
    "#   \"/kaggle/input/mission-impassable/piloted_flight-08p-lemniscate.h5\",\n",
    "#     \"/kaggle/input/mission-impassable/autonomous_flight-15a-trackRATM.h5\",\n",
    "\n",
    "\n",
    "dataset = GateDetectionDataset(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "# Create training set loader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=config[\"num_workers_train_loader\"],\n",
    ")\n",
    "\n",
    "# Create validation set loader\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=config[\"num_workers_val_loader\"],\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def matching_loss(\n",
    "    pred,\n",
    "    target,\n",
    "    coord_loss_weight=1,\n",
    "    missing_target_penalty=16,  # Penalty for missing a target gate\n",
    "):\n",
    "    \"\"\"\n",
    "    Custom loss function using soft matching (softmax) to match predicted gates with target gates,\n",
    "    ensuring that each target gate is predicted at least once.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): Predicted tensor of shape (batch_size, 6, 13) with 6 predicted gates.\n",
    "        target (torch.Tensor): Target tensor of shape (batch_size, n_targets, 13), where n_targets <= 6.\n",
    "        coord_loss_weight (float): Weight for the coordinate loss.\n",
    "        penalty (float): Penalty to apply when fewer predicted gates are matched than target gates.\n",
    "        missing_target_penalty (float): Penalty for missing a target gate.\n",
    "\n",
    "    Returns:\n",
    "        loss (torch.Tensor): Calculated loss for the batch.\n",
    "    \"\"\"\n",
    "    batch_size = pred.size(0)\n",
    "    total_loss = torch.zeros(1, device=pred.device, requires_grad=True)\n",
    "    for i in range(batch_size):\n",
    "        pred_gates = pred[i].to(pred.device)  # Ensure it's on the correct device\n",
    "        target_gates = target[i].to(pred.device)  # Ensure it's on the correct device\n",
    "\n",
    "        n_targets = target_gates.size(0)\n",
    "\n",
    "        # Extract x and y coordinates (x1, y1, x2, y2, ...)\n",
    "        pred_coords = pred_gates[..., [0, 1, 3, 4, 6, 7, 9, 10]]  # Shape: (6, 8)\n",
    "        target_coords = target_gates[\n",
    "            ..., [0, 1, 3, 4, 6, 7, 9, 10]\n",
    "        ]  # Shape: (n_targets, 8)\n",
    "\n",
    "        pred_vis = pred_gates[..., [2, 5, 8, 11]]\n",
    "        target_vis = target_gates[..., [2, 5, 8, 11]]\n",
    "\n",
    "        #         print(\"shape pred\", pred_coords.shape, \"shape target\", target_coords.shape)\n",
    "\n",
    "        coord_dist = torch.sum(\n",
    "            (pred_coords.unsqueeze(1) - target_coords.unsqueeze(0)) ** 2, dim=-1\n",
    "        )  # Shape: (6, n_targets)\n",
    "        #         print(f\"coord dist\",coord_dist)\n",
    "\n",
    "        # Shape: (num_predicted_gates, num_target_gates)\n",
    "        vis_dist = torch.sum(\n",
    "            torch.abs(pred_vis.unsqueeze(1) - target_vis.unsqueeze(0)), dim=-1\n",
    "        )  # Shape: (6, n_targets)\n",
    "\n",
    "        # Total cost matrix based on coordinate distances\n",
    "        cost_matrix = coord_loss_weight * coord_dist + vis_dist / 20\n",
    "        #         print(f\"cost matrix\",cost_matrix)\n",
    "\n",
    "        best_matches = torch.argmin(\n",
    "            cost_matrix, dim=1\n",
    "        )  # Shape: (6,), contains indices of closest target for each prediction\n",
    "\n",
    "        #         print(f\"best matches\",best_matches)\n",
    "\n",
    "        # Now compute the matching loss using the argmin assignments\n",
    "        assigned_costs = cost_matrix[\n",
    "            torch.arange(cost_matrix.size(0)), best_matches\n",
    "        ]  # Shape: (6,), get the corresponding costs\n",
    "\n",
    "        #         print(f\"assigned costs\", assigned_costs)\n",
    "\n",
    "        # Sum the assigned costs\n",
    "        matching_loss = torch.sum(assigned_costs)\n",
    "\n",
    "        temperature = 0.1\n",
    "        # Softmax over the target gates for each predicted gate\n",
    "        soft_assignment = F.softmax(-cost_matrix, dim=1)\n",
    "\n",
    "        # Calculate the matching loss (soft assignment weighted by the cost)\n",
    "        matching_loss = torch.sum(soft_assignment * cost_matrix)\n",
    "\n",
    "        # Enforce that the maximum assignment value for each target must be >= 0.7\n",
    "        max_assignment_per_target = torch.max(soft_assignment, dim=0)[\n",
    "            0\n",
    "        ]  # Get maximum assignment for each target gate\n",
    "\n",
    "        # Penalize if any maximum assignment is less than the threshold (0.7)\n",
    "        missing_target_penalty_term = (\n",
    "            torch.sum((max_assignment_per_target < 0.8).float().to(pred.device))\n",
    "            * missing_target_penalty\n",
    "        )\n",
    "\n",
    "        # Combine losses\n",
    "        total_loss = total_loss + matching_loss + missing_target_penalty_term\n",
    "\n",
    "    # Average loss over the batch\n",
    "    total_loss = total_loss / batch_size\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_loader, model, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_error_tensor = []\n",
    "    val_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Get model predictions and confidence scores\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Post-process predictions before calculating the loss\n",
    "\n",
    "            # Calculate loss using the loss function\n",
    "            loss = matching_loss(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Append loss to error tensor for tracking performance\n",
    "            val_error_tensor.append(loss.item())\n",
    "            val_pred.append(outputs)\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    # Convert error tensor to a torch tensor\n",
    "    val_error_tensor = torch.tensor(val_error_tensor, device=device)\n",
    "    val_mean = val_error_tensor.mean().item()\n",
    "    val_median = val_error_tensor.median().item()\n",
    "\n",
    "    val_perf = (val_mean, val_median, val_error_tensor)\n",
    "\n",
    "    return val_loss, val_perf, val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_epoch(train_loader, model, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_error_tensor = []\n",
    "\n",
    "    total_batches = len(train_loader)\n",
    "    print_interval = max(total_batches // 20, 1)  # Print every 5% of total batches\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        # Move data to the GPU\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = matching_loss(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_error_tensor.append(loss.item())\n",
    "\n",
    "        # Print progress every 5% of the training loop\n",
    "        if (batch_idx + 1) % print_interval == 0:\n",
    "            print(\n",
    "                f\"Progress: {(batch_idx + 1) / total_batches * 100:.2f}% - Loss: {loss.item():.4f}\"\n",
    "            )\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_error_tensor = torch.tensor(train_error_tensor, device=device)\n",
    "    train_mean = train_error_tensor.mean().item()\n",
    "    train_median = train_error_tensor.median().item()\n",
    "    train_perf = (train_mean, train_median, train_error_tensor)\n",
    "\n",
    "    return train_loss, train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with the provided epoch loop\n",
    "# Assuming you have defined the necessary elements: train_loader, val_loader, model, optimizer, device, and config\n",
    "exp_name = \"NEWMODEL\"\n",
    "epochs = config[\"epochs\"]\n",
    "print(f\"learning rate: {config['lr']}\")\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "    # Train the model for one epoch\n",
    "    train_loss, train_perf = train_epoch(train_loader, model, optimizer, device)\n",
    "    train_mean, train_median, train_error_tensor = train_perf\n",
    "\n",
    "    # Evaluate the model on validation set\n",
    "    val_loss, val_perf, val_pred = evaluate(val_loader, model, device)\n",
    "    val_mean, val_median, val_error_tensor = val_perf\n",
    "\n",
    "    print(\"val_loss_mean\", val_mean)\n",
    "    print(\"train_loss_mean\", train_mean)\n",
    "\n",
    "    # Clear GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
