{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_config(config_path: str) -> dict:\n",
    "\n",
    "    # Open the YAML file, load its content, and return dictionary\n",
    "    with open(config_path, \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "\n",
    "config = load_config(\"config/competition.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datalaoding and model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_channels=3, num_targets=6):\n",
    "        \"\"\"\n",
    "        Custom regression model for detecting target corners with (x, y, z, visibility) coordinates.\n",
    "        - input_channels: Number of input channels in the image RGB = 3\n",
    "        - num_targets: Maximum number of targets per image.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_targets = num_targets\n",
    "\n",
    "        # Backbone Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Fully Connected Layers for Regression\n",
    "        self.fc1 = nn.Linear(\n",
    "            512 * 30 * 40, 1024\n",
    "        )  # Adjust input size based on image resolution after convolutions\n",
    "        self.fc2 = nn.Linear(\n",
    "            1024, self.num_targets * 12\n",
    "        )  # Output size: [num_targets, 12]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extraction with convolutional layers\n",
    "        x = F.relu(self.conv1(x))  # -> [batch, 64, H, W]\n",
    "        x = F.max_pool2d(\n",
    "            x, kernel_size=2, stride=2\n",
    "        )  # Downsampling -> [batch, 64, H/2, W/2]\n",
    "\n",
    "        x = F.relu(self.conv2(x))  # -> [batch, 128, H/2, W/2]\n",
    "        x = F.max_pool2d(\n",
    "            x, kernel_size=2, stride=2\n",
    "        )  # Downsampling -> [batch, 128, H/4, W/4]\n",
    "\n",
    "        x = F.relu(self.conv3(x))  # -> [batch, 256, H/4, W/4]\n",
    "        x = F.max_pool2d(\n",
    "            x, kernel_size=2, stride=2\n",
    "        )  # Downsampling -> [batch, 256, H/8, W/8]\n",
    "\n",
    "        x = F.relu(self.conv4(x))  # -> [batch, 512, H/8, W/8]\n",
    "        x = F.max_pool2d(\n",
    "            x, kernel_size=2, stride=2\n",
    "        )  # Downsampling -> [batch, 512, H/16, W/16]\n",
    "\n",
    "        # Flatten before feeding into fully connected layers\n",
    "        x = x.view(x.size(0), -1)  # Flatten -> [batch, 512 * (H/16) * (W/16)]\n",
    "\n",
    "        # Regression layers\n",
    "        x = F.relu(self.fc1(x))  # Fully connected layer -> [batch, 1024]\n",
    "        x = self.fc2(x)  # Final layer -> [batch, num_targets * 12]\n",
    "\n",
    "        # Reshape to [batch, num_targets, 12]\n",
    "        x = x.view(-1, self.num_targets, 12)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining data loaders and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from dataloading import DroneDataset\n",
    "\n",
    "data_path = \"/workspaces/AE4353-Y24/competition/data/Autonomous\"\n",
    "dataset = DroneDataset(data_path)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create training set loader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"batchsize_train\"],\n",
    "    shuffle=config[\"shuffle_train\"],\n",
    "    num_workers=config[\"num_workers_train_loader\"],\n",
    ")\n",
    "\n",
    "# Create validation set loader\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config[\"batchsize_val\"],\n",
    "    shuffle=config[\"shuffle_val\"],\n",
    "    num_workers=config[\"num_workers_val_loader\"],\n",
    ")\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=config[\"lr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def soft_matching_loss(gt_gates, pred_gates, p_max=10.0):\n",
    "    \"\"\"\n",
    "    Calculate a soft matching loss between ground truth and predicted gates using a differentiable approach.\n",
    "    Pads gt_gates or pred_gates to have the same number of gates if they are different.\n",
    "\n",
    "    Args:\n",
    "        gt_gates: Ground truth gates, shape (B, N, 12).\n",
    "        pred_gates: Predicted gates, shape (B, M, 12).\n",
    "        p_max: Maximum penalty for unmatched gates.\n",
    "\n",
    "    Returns:\n",
    "        loss: Calculated differentiable loss tensor.\n",
    "    \"\"\"\n",
    "    # Get batch size, number of gt gates, and number of pred gates\n",
    "    batch_size = gt_gates.size(0)\n",
    "    num_gt = gt_gates.size(1)\n",
    "    num_pred = pred_gates.size(1)\n",
    "\n",
    "    # Pad either gt_gates or pred_gates to have the same number of gates\n",
    "    if num_gt > num_pred:\n",
    "        # Pad pred_gates to match gt_gates along the gates dimension\n",
    "        padding = (0, 0, 0, num_gt - num_pred)  # Pad along the gates dimension\n",
    "        pred_gates = F.pad(pred_gates, padding, value=0)\n",
    "    elif num_gt < num_pred:\n",
    "        # Pad gt_gates to match pred_gates along the gates dimension\n",
    "        padding = (0, 0, 0, num_pred - num_gt)  # Pad along the gates dimension\n",
    "        gt_gates = F.pad(gt_gates, padding, value=0)\n",
    "\n",
    "    # Flatten to shape (batch_size * num_gates, 12)\n",
    "    gt_gates_flat = gt_gates.view(-1, 12)\n",
    "    pred_gates_flat = pred_gates.view(-1, 12)\n",
    "\n",
    "    # Extract coordinates and visibility information\n",
    "    gt_coords = gt_gates_flat.view(-1, 4, 3)[:, :, :2]  # Shape (N, 4, 2)\n",
    "    pred_coords = pred_gates_flat.view(-1, 4, 3)[:, :, :2]  # Shape (N, 4, 2)\n",
    "\n",
    "    # Calculate pairwise distances between ground truth and predicted gates\n",
    "    distances = torch.cdist(gt_coords, pred_coords, p=2)  # Shape (N, N, 4)\n",
    "    distances = distances.mean(dim=-1)  # Average over corners, shape (N, N)\n",
    "\n",
    "    # Apply softmax to get \"soft assignment\" scores\n",
    "    scores = F.softmax(\n",
    "        -distances, dim=1\n",
    "    )  # Negative to get matching scores, shape (N, N)\n",
    "\n",
    "    # Calculate weighted matching score\n",
    "    matching_loss = (\n",
    "        (scores * distances).sum(dim=1).mean()\n",
    "    )  # Mean over ground truth gates\n",
    "\n",
    "    # Penalty for unmatched gates\n",
    "    unmatched_penalty = p_max * (1 - scores.max(dim=1)[0]).mean()\n",
    "\n",
    "    # Total loss is the sum of matching loss and unmatched penalty\n",
    "    loss = matching_loss + unmatched_penalty\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, p_max=10.0):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a model on a given dataloader using PyTorch tensors.\n",
    "\n",
    "    Args:\n",
    "        dataloader (torch.utils.data.DataLoader): The dataloader containing the evaluation data.\n",
    "        model (torch.nn.Module): The model to be evaluated.\n",
    "        p_max (float): Maximum penalty for matching.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the average matching score (loss), evaluation metric (mean, median, and all values), and predictions.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    metrics = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():  # No need to calculate gradients for evaluation\n",
    "        for batch in tqdm(dataloader, desc=\"Eval\", leave=False):\n",
    "            inputs, targets_gt = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets_gt = targets_gt.to(device)\n",
    "\n",
    "            # Forward pass to get predicted gates\n",
    "            pred_gates = model(inputs)\n",
    "\n",
    "            # Calculate matching score between ground truth and predicted gates using PyTorch tensors\n",
    "            total_matching_score = soft_matching_loss(targets_gt, pred_gates, p_max)\n",
    "\n",
    "            # Use the matching score as loss\n",
    "            total_loss += total_matching_score\n",
    "\n",
    "            # Store results\n",
    "            metrics.append(total_matching_score)\n",
    "            all_predictions.extend(pred_gates.tolist())\n",
    "\n",
    "    # Convert to tensor for easier calculations\n",
    "    metrics = torch.tensor(metrics)\n",
    "    all_predictions = torch.tensor(all_predictions)\n",
    "\n",
    "    return (\n",
    "        total_loss / len(dataloader),\n",
    "        (metrics.mean().item(), metrics.median().item(), metrics),\n",
    "        all_predictions,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainging Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def train_epoch(train_loader, val_loader, model, optimizer, p_max=10.0):\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch using the provided data loaders, model, optimizer, and criterion.\n",
    "    Args:\n",
    "        train_loader (torch.utils.data.DataLoader): Data loader for the training set.\n",
    "        val_loader (torch.utils.data.DataLoader): Data loader for the validation set.\n",
    "        model (torch.nn.Module): The model to be trained.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
    "        criterion (torch.nn.Module): The loss function used for training.\n",
    "    Returns:\n",
    "        tuple: A tuple containing the training loss, training performance, validation performance, and validation predictions.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        inputs, targets_gt = batch\n",
    "        inputs = inputs.to(device)\n",
    "        targets_gt = targets_gt.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get predicted gates\n",
    "        pred_gates = model(inputs)\n",
    "        # Calculate matching score between ground truth and predicted gates using PyTorch tensors\n",
    "        loss = soft_matching_loss(targets_gt, pred_gates, p_max)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss, train_performance, _ = evaluate(train_loader, model)\n",
    "    _, val_performance, val_pred = evaluate(val_loader, model)\n",
    "\n",
    "    return train_loss, train_performance, val_performance, val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ff1997427d438888c40d0d9deb1e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eaaaac07698460cbc45b9be1cd85aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 12\u001b[0m\n\u001b[1;32m      4\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, comment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      7\u001b[0m     (\n\u001b[1;32m      8\u001b[0m         train_loss,\n\u001b[1;32m      9\u001b[0m         (train_error_mean, train_error_median, train_error_tensor),\n\u001b[1;32m     10\u001b[0m         (val_err_mean, val_err_median, val_error_tensor),\n\u001b[1;32m     11\u001b[0m         val_pred,\n\u001b[0;32m---> 12\u001b[0m     ) \u001b[38;5;241m=\u001b[39m train_epoch(train_loader, val_loader, model, optimizer)\n\u001b[1;32m     13\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_loss, epoch)\n\u001b[1;32m     14\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError/train/mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_error_mean, epoch)\n",
      "Cell \u001b[0;32mIn[85], line 22\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, val_loader, model, optimizer, p_max)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     21\u001b[0m     inputs, targets_gt \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 22\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     23\u001b[0m     targets_gt \u001b[38;5;241m=\u001b[39m targets_gt\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     25\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "exp_name = \"First Run\"\n",
    "writer = SummaryWriter(f\"runs/{exp_name}\", comment=\"\")\n",
    "\n",
    "for epoch in tqdm(range(config[\"epochs\"]), desc=\"Epochs\"):\n",
    "    (\n",
    "        train_loss,\n",
    "        (train_error_mean, train_error_median, train_error_tensor),\n",
    "        (val_err_mean, val_err_median, val_error_tensor),\n",
    "        val_pred,\n",
    "    ) = train_epoch(train_loader, val_loader, model, optimizer)\n",
    "    writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Error/train/mean\", train_error_mean, epoch)\n",
    "    writer.add_scalar(\"Error/train/median\", train_error_median, epoch)\n",
    "    writer.add_scalar(\"Error/val/mean\", val_err_mean, epoch)\n",
    "    writer.add_scalar(\"Error/val/median\", val_err_median, epoch)\n",
    "    writer.add_histogram(\"Error/val\", train_error_tensor, epoch)\n",
    "    writer.add_histogram(\"Pred/val\", val_pred, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AE4353",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
